# ğŸš€ Guide de DÃ©ploiement - Web Scraper Pro

Guide complet pour dÃ©ployer l'application web sur diffÃ©rentes plateformes **100% GRATUITES**.

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Test Local](#test-local)
2. [DÃ©ploiement sur Render.com (RecommandÃ©)](#dÃ©ploiement-sur-rendercom)
3. [DÃ©ploiement sur Railway](#dÃ©ploiement-sur-railway)
4. [DÃ©ploiement sur Fly.io](#dÃ©ploiement-sur-flyio)
5. [Configuration des APIs](#configuration-des-apis)
6. [DÃ©pannage](#dÃ©pannage)

---

## âœ… Test Local

Avant de dÃ©ployer, testez l'application localement :

```bash
# 1. Installer les dÃ©pendances
pip install -r requirements.txt

# 2. Lancer l'application
python app.py

# 3. Ouvrir dans le navigateur
http://localhost:5000
```

Si tout fonctionne â†’ Passez au dÃ©ploiement en ligne !

---

## ğŸŒŸ DÃ©ploiement sur Render.com (RECOMMANDÃ‰)

### Pourquoi Render.com ?
- âœ… 100% Gratuit
- âœ… HTTPS automatique
- âœ… DÃ©ploiement en 5 minutes
- âœ… Pas de carte bancaire requise
- âœ… Interface ultra simple

### Ã‰tape 1 : PrÃ©parer le Code

1. **CrÃ©er un compte GitHub** (si pas dÃ©jÃ  fait) : https://github.com/signup

2. **CrÃ©er un nouveau dÃ©pÃ´t** :
   - Nom : `web-scraper-pro`
   - Public ou PrivÃ© (au choix)
   - Ne pas initialiser avec README

3. **Pousser le code sur GitHub** :
```bash
cd /Users/sylvainboue/web-scraper
git init
git add .
git commit -m "Initial commit - Web Scraper Pro"
git branch -M main
git remote add origin https://github.com/TON-USERNAME/web-scraper-pro.git
git push -u origin main
```

### Ã‰tape 2 : DÃ©ployer sur Render

1. **CrÃ©er un compte Render** : https://render.com/
   - Inscription gratuite
   - Connecter avec GitHub (recommandÃ©)

2. **CrÃ©er un nouveau Web Service** :
   - Cliquer sur "New +" â†’ "Web Service"
   - SÃ©lectionner le dÃ©pÃ´t `web-scraper-pro`
   - Cliquer sur "Connect"

3. **Configuration** :
   - **Name** : `web-scraper-pro` (ou votre choix)
   - **Region** : Choisir la plus proche
   - **Branch** : `main`
   - **Runtime** : `Python 3`
   - **Build Command** : `pip install -r requirements.txt`
   - **Start Command** : `gunicorn app:app`
   - **Instance Type** : `Free` âœ…

4. **Variables d'environnement** (Optionnel - configurable plus tard) :
   - Cliquer sur "Advanced"
   - Ajouter :
     ```
     PAPPERS_API_KEY = votre_clÃ©
     HUNTER_API_KEY = votre_clÃ©
     ```

5. **DÃ©ployer** :
   - Cliquer sur "Create Web Service"
   - Attendre 5-10 minutes (premiÃ¨re fois)
   - âœ… Votre app sera disponible Ã  : `https://web-scraper-pro.onrender.com`

### Ã‰tape 3 : Configurer les APIs

1. Ouvrir votre app : `https://web-scraper-pro.onrender.com`
2. Cliquer sur "âš™ï¸ Configuration"
3. Ajouter vos clÃ©s API Pappers et Hunter
4. Cliquer sur "Sauvegarder"

### ğŸ‰ TerminÃ© ! Votre Ã©quipe peut maintenant accÃ©der Ã  l'outil !

---

## ğŸš‚ DÃ©ploiement sur Railway

Alternative gratuite Ã  Render.

### Ã‰tapes :

1. **CrÃ©er un compte** : https://railway.app/
2. **Nouveau Projet** â†’ "Deploy from GitHub repo"
3. **SÃ©lectionner** `web-scraper-pro`
4. Railway dÃ©tecte automatiquement Python
5. **Ajouter variables d'environnement** :
   - Settings â†’ Variables
   - Ajouter `PAPPERS_API_KEY` et `HUNTER_API_KEY`
6. **DÃ©ployer** automatiquement
7. **GÃ©nÃ©rer domaine** : Settings â†’ Generate Domain

URL finale : `https://web-scraper-pro.up.railway.app`

**Limite gratuite** : 500 heures/mois (suffisant pour petite Ã©quipe)

---

## âœˆï¸ DÃ©ploiement sur Fly.io

Pour utilisateurs avancÃ©s.

### Ã‰tapes :

1. **Installer Fly CLI** :
```bash
curl -L https://fly.io/install.sh | sh
```

2. **Se connecter** :
```bash
flyctl auth login
```

3. **Lancer l'app** :
```bash
cd /Users/sylvainboue/web-scraper
flyctl launch
```

4. **Configurer** :
   - App name : `web-scraper-pro`
   - Region : Choisir la plus proche
   - PostgreSQL : Non
   - Redis : Non

5. **DÃ©finir secrets** :
```bash
flyctl secrets set PAPPERS_API_KEY=votre_clÃ©
flyctl secrets set HUNTER_API_KEY=votre_clÃ©
```

6. **DÃ©ployer** :
```bash
flyctl deploy
```

URL finale : `https://web-scraper-pro.fly.dev`

---

## ğŸ”‘ Configuration des APIs

### Pappers.fr (RecommandÃ© pour entreprises franÃ§aises)

1. **S'inscrire** : https://www.pappers.fr/api
2. **Obtenir la clÃ©** : Dashboard â†’ API Key
3. **Ajouter dans l'app** : Configuration â†’ Pappers API Key

### Hunter.io (Emails professionnels)

1. **S'inscrire** : https://hunter.io/users/sign_up
2. **Obtenir la clÃ©** : https://hunter.io/api_keys
3. **Ajouter dans l'app** : Configuration â†’ Hunter API Key

### Sans APIs (Mode gratuit basique)

L'app fonctionne aussi **sans aucune clÃ© API** :
- âœ… Scraping : 100% fonctionnel
- âœ… Domain Finder : Clearbit gratuit (pas de clÃ© requise)
- âœ… Enrichment : Scraping web uniquement
- âš ï¸ Moins de donnÃ©es (pas d'infos lÃ©gales, moins d'emails)

---

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨me : L'app se met en veille

**Render.com gratuit** : L'app se met en veille aprÃ¨s 15min d'inactivitÃ©.

**Solutions** :
1. Accepter 30sec de dÃ©marrage au premier accÃ¨s
2. Utiliser un "pinger" gratuit : https://uptimerobot.com/
3. Passer au plan payant Render ($7/mois)

### ProblÃ¨me : Timeout lors du scraping

**Cause** : Render limite Ã  30 secondes par requÃªte HTTP.

**Solutions** :
1. L'app utilise du threading (pas affectÃ©)
2. Les jobs tournent en arriÃ¨re-plan
3. RafraÃ®chir la page pendant le job

### ProblÃ¨me : Erreur de dÃ©ploiement

**VÃ©rifier** :
1. `requirements.txt` est bien prÃ©sent
2. `Procfile` est bien prÃ©sent
3. `runtime.txt` spÃ©cifie Python 3.11

**Commandes de debug** :
```bash
# Voir les logs Render
# Dashboard â†’ Web Service â†’ Logs

# Tester localement
python app.py
```

### ProblÃ¨me : APIs ne fonctionnent pas

**VÃ©rifier** :
1. ClÃ©s API bien enregistrÃ©es (Configuration)
2. ClÃ©s valides (tester sur sites officiels)
3. Quotas non dÃ©passÃ©s

### ProblÃ¨me : Selenium ne fonctionne pas en production

**Note** : Selenium (scraping) ne fonctionne PAS sur les plateformes gratuites car Chrome n'est pas installÃ©.

**Solutions** :
1. **Option A** : Scraper en local, uploader les rÃ©sultats
2. **Option B** : Utiliser scrapers sans Selenium (BeautifulSoup uniquement)
3. **Option C** : DÃ©ployer sur serveur avec Chrome (DigitalOcean, AWS)

**Pour Equipauto spÃ©cifiquement** :
- Scraper en local une fois
- Uploader `equipauto_exhibitors_clean.json` dans l'app
- Utiliser Domain Finder et Enrichment online

---

## ğŸ“Š Comparaison des Plateformes

| Plateforme | Gratuit | HTTPS | Facile | Selenium | Limite |
|------------|---------|-------|--------|----------|--------|
| **Render** | âœ… | âœ… | â­â­â­ | âŒ | Sleep aprÃ¨s 15min |
| **Railway** | âœ… | âœ… | â­â­ | âŒ | 500h/mois |
| **Fly.io** | âœ… | âœ… | â­ | âŒ | 3 apps max |
| **Heroku** | âŒ | âœ… | â­â­â­ | âŒ | Payant ($7/mois) |
| **DigitalOcean** | âŒ | âœ… | â­ | âœ… | $5/mois |

**Recommandation** : Render.com pour dÃ©buter !

---

## ğŸ¯ Workflow RecommandÃ© pour Ã‰quipe

### Pour 100% gratuit :

1. **Scraping** : Faire en local (Selenium fonctionne)
2. **Uploader** : Mettre les JSON dans l'app dÃ©ployÃ©e
3. **Domain Finder** : Utiliser l'app en ligne
4. **Enrichment** : Utiliser l'app en ligne avec APIs

### Pour production (petit budget) :

1. **Serveur DigitalOcean** : $5/mois
2. **Tout fonctionne** : Scraping + Domain + Enrichment
3. **Chrome installÃ©** : Selenium opÃ©rationnel
4. **URL personnalisÃ©e** : `https://scraper.ton-entreprise.com`

---

## ğŸ” SÃ©curitÃ©

### Pour usage en Ã©quipe :

1. **Ajouter authentification** (optionnel) :
   - ImplÃ©menter Flask-Login
   - CrÃ©er comptes utilisateurs
   - ProtÃ©ger les routes

2. **Variables d'environnement** :
   - Ne jamais commit les clÃ©s API
   - Utiliser `.env` local
   - Variables d'env sur plateforme de dÃ©ploiement

3. **Rate limiting** :
   - ImplÃ©menter Flask-Limiter
   - Limiter requÃªtes par IP

---

## ğŸ“ Support

**Questions ?**
- Render Docs : https://render.com/docs
- Railway Docs : https://docs.railway.app
- Fly Docs : https://fly.io/docs

**ProblÃ¨mes spÃ©cifiques Ã  l'app ?**
- VÃ©rifier les logs de dÃ©ploiement
- Tester en local d'abord
- VÃ©rifier les variables d'environnement

---

## âœ… Checklist de DÃ©ploiement

- [ ] Code sur GitHub
- [ ] Compte Render.com crÃ©Ã©
- [ ] Web Service crÃ©Ã© et dÃ©ployÃ©
- [ ] URL fonctionnelle (ex: https://web-scraper-pro.onrender.com)
- [ ] ClÃ©s API Pappers ajoutÃ©es (optionnel)
- [ ] ClÃ©s API Hunter ajoutÃ©es (optionnel)
- [ ] Test complet : Scraping â†’ Domains â†’ Enrichment
- [ ] URL partagÃ©e avec l'Ã©quipe

**Temps estimÃ©** : 15-20 minutes pour premier dÃ©ploiement

---

## ğŸ‰ FÃ©licitations !

Votre Ã©quipe a maintenant accÃ¨s Ã  un outil professionnel de scraping et enrichissement de donnÃ©es, 100% gratuit, accessible via HTTPS depuis n'importe oÃ¹ !

**URL Ã  partager** : `https://TON-APP.onrender.com`

Happy Scraping! ğŸš€
